{
 "metadata": {
  "name": "",
  "signature": "sha256:a3ce99a561017262dcbae0c30631e2a31d72ab401feb12e5ddc2324709582c97"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "(In order to load the stylesheet of this notebook, execute the last code cell in this notebook)"
     ]
    },
    {
     "cell_type": "heading",
     "level": 1,
     "metadata": {},
     "source": [
      "Analyze the data from the Mayor's 24-hour hotline in Boston using Pandas"
     ]
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "Introduction "
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "In this assignment, we will practice some basic skills on working with data. We will see how to read, access, clean, filter and plot a dataset.\n",
      "\n",
      "---------------------------"
     ]
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "Step 1. Downaloading the data"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "The data that we will be using are freely available online, by the [City of Boston](https://data.cityofboston.gov/). A brief description of the 311 service can be found [here](http://www.cityofboston.gov/mayor/24/). You can download the whole dataset, which extends from 2011 until now (updated every day) from [here](https://data.cityofboston.gov/City-Services/Mayor-s-24-Hour-Hotline-Service-Requests/awu8-dc52?). However, it contains over 555,000 records and, as a result, it's more than 245 MB in size. In the homework repository, you can find a small part of it that covers the months of January-February 2015, under the filename `cases_2015.csv`."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "During these two months, Boston experienced one of the highest levels of snowfalls. We will take this opportunity and see how this situation affected the 311 center. We will also be using data from [NOAA National Climatic Data Center](http://www.ncdc.noaa.gov/cdo-web/) regarding the levels of snowfall for the dates that we are interested in. This dataset is also available in our repository for your convenience under the file `snow.csv`. You can read its documentation [here](http://www.ncdc.noaa.gov/cdo-web/datasets)."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "-----------------"
     ]
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "Step 2. Reading the data"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "The first thing we want to do is load the data as Pandas *DataFrames*."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%matplotlib inline\n",
      "import pandas as pd\n",
      "import seaborn as sns\n",
      "from datetime import datetime\n",
      "from matplotlib import pyplot as plt"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "boston = pd.read_csv('cases_2015.csv')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "We need to take a brief look at the data, so that we get an intuition about what we are dealing with. Your first task is to do just that: print some part of the dataset **(5 pts)**"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Print part of the dataset here"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Another useful thing is to get a short summary of the columns and their data types. Make a call to the required function for this **(5 pts)**"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Print information about the columns of the dataset"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "As you can see, the `OPEN_DT`, `TARGET_DT`, and `CLOSED_DT` columns, all of which should be dates, have been misclassified as `object` instead of datetime. Re-write the code that reads from a csv, in order to parse the above columns as datetimes. **(5 pts)**"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Read the date columns as datetime objects"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Make sure that the column data types are exactly as expected:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Print the data types of the columns again"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "Step 3. Filtering and plotting the data"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Now that we read the data and took a quick look, we can start playing around with it. As you have already noticed, there is very little documentation on the dataset itself. In such occasions, we need to look at the dataset very extensively, to get a good feel of its structure. This part, together with what we will do next, is a significant part of the *data cleaning* process."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "To practice our filtering skills, let's try to isolate the cases that were opened in February **(5 pts)**"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Write code that filters the dataframe and keeps only the cases that were opened in February"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Can you do the same thing, but only for the cases that are still remaining open? **(5 pts)**"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Write a code that also filters for open cases"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Great! Now, let's check all the different values of the column `CASE_TITLE` together with their counts **(5 pts)**"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Write code that prints the different values of the column 'CASE_TITLE'\n",
      "# and the count for the occurencies of each value in the boston dataframe"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "During this process, you may encounter many strange things, that look like outliers. For example, you may notice that there are many values for `CASE_TITLE` which only occur once. One such example is the category\n",
      "```\n",
      "\"missing pb cover/printed for jim\"\n",
      "```\n",
      "I really wonder what this means! Try retrieving and printing the whole row **(5 pts)**"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Print the row tht has CASE_TITLE \"missing pb cover/printed for jim\""
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "There's another category which seems interesting, `Heat - Excessive Insufficient`. Write code that prints the first 10 rows of the dataset that have `CASE_TITLE` which starts with \"Heat\" and see if you can understand what this stands for **(15 pts)**"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Now, let's plot (preferably with horizontal bars) the counts for all the `CASE_TITLE`s that occur more than 250 times in the dataset. **(5 pts)**"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Plots the high-occuring categories for cases as a horizontal histogram."
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "As you can see, the most common categories are related to snow. Let us see which neighborhoods were mostly affected by snow problems. This information is saved under the `neighborhood` column. Make a plot (similar to the one above, like a horizontal histogram) that for each neighborhood shows the number of snow-related calls made from there. **(5 pts)**"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "Step 3. Advanced filtering & joins"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "By now, you should have noticed that, for each day, there are multiple records in our dataframe. Use the `groupby` function to get, for each day, the counts for all the case categories. Plot the result for the top 5 categories as you see fit. **(20 pts)**"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Write your code here"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Let's see how this trend compares to the snowfall. First, we need to read the data from `snow.csv`"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Read the dataframe\n",
      "snow_data = pd.read_csv(\"snow.csv\",parse_dates=[1])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "According to the documentation, the column `SNOW` has the values for the snowfall, in mm. However, the dataset we have has information from many different stations around Boston. Aggregate all their measurements and transform the result to centimeters. Finally, plot the result **(10 pts)**"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Write your code here"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "Step 4. Matching trends"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "The last thing we will do is to join the snowfall dataframe with that of the top 5 categories of calls, per day. Don't forget to fill the NaN values with 0. You want to do an outer join (if there are calls for a day but no snowfall data, we want to create a 0 record). Save that to a dataframe called `calls_on_snow`. The first 5 columns should be the counts for the categories, and the 6th will be the snowfall data. **(10 pts)**"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Now, you can show the connection of the two trends (the calls and the snow) in a plot. I provide some sample code, but you should also try your own versions."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "fig, axes = plt.subplots(nrows=2,figsize=(12,5), sharex=True)\n",
      "\n",
      "calls_on_snow.ix[:,0:5].plot(ax=axes[0])\n",
      "calls_on_snow.ix[:,5].plot(ax=axes[1],label=\"snowfall (in cm)\", color='gray')\n",
      "\n",
      "axes[0].set_title(\"The effect of the winter snowstorms on Boston's 311 Hotline for 2015\")\n",
      "axes[0].set_ylabel(\"# Calls\")\n",
      "axes[1].set_ylabel(\"Snowfall in cm\")\n",
      "axes[1].set_xlabel(\"Date\")\n",
      "axes[0].xaxis.grid(False)\n",
      "axes[1].xaxis.grid(False)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "The result should look something like this:\n",
      "\n",
      "\n",
      "![The calls to 311 are peaking after each snowstorm](final_plot.png)"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Code for setting the style of the notebook\n",
      "from IPython.core.display import HTML\n",
      "def css_styling():\n",
      "    styles = open(\"../../theme/custom.css\", \"r\").read()\n",
      "    return HTML(styles)\n",
      "css_styling()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "html": [
        "<link href='http://fonts.googleapis.com/css?family=EB+Garamond' rel='stylesheet' type='text/css'>\n",
        "<link href='http://fonts.googleapis.com/css?family=Alegreya+Sans:100,300,400,500,700,800,900,100italic,300italic,400italic,500italic,700italic,800italic,900italic' rel='stylesheet' type='text/css'>\n",
        "<link href='http://fonts.googleapis.com/css?family=Source+Code+Pro:300,400' rel='stylesheet' type='text/css'>\n",
        "<style>\n",
        "    @font-face {\n",
        "        font-family: \"Computer Modern\";\n",
        "        src: url('http://mirrors.ctan.org/fonts/cm-unicode/fonts/otf/cmunss.otf');\n",
        "    }\n",
        "    .code_cell {\n",
        "        width: 105ex !important ;\n",
        "        margin-bottom: 15px !important;\n",
        "    }\n",
        "    div.cell {\n",
        "        margin-left: auto;\n",
        "        margin-right: auto;\n",
        "        width: 70%;\n",
        "    }    \n",
        "    div.cell.selected {\n",
        "        border: thin rgba(171, 171, 171, 0.5) dashed;\n",
        "    }\n",
        "    h1 {\n",
        "        font-family: 'Alegreya Sans', sans-serif;\n",
        "    }\n",
        "    h2 {\n",
        "        font-family: 'EB Garamond', serif;\n",
        "    }\n",
        "    h3 {\n",
        "        font-family: 'EB Garamond', serif;\n",
        "        margin-top:12px;\n",
        "        margin-bottom: 3px;\n",
        "    }\n",
        "    h4 {\n",
        "        font-family: 'EB Garamond', serif;\n",
        "    }\n",
        "    h5 {\n",
        "        font-family: 'Alegreya Sans', sans-serif;\n",
        "    }\n",
        "    div.text_cell_render {\n",
        "        font-family: 'EB Garamond',Computer Modern, \"Helvetica Neue\", Arial, Helvetica, Geneva, sans-serif;\n",
        "        line-height: 145%;\n",
        "        font-size: 140%;\n",
        "    }\n",
        "    div.input_area {\n",
        "        border-color: rgba(0,0,0,0.10) !important;\n",
        "        background: #fafafa;\n",
        "    }\n",
        "    .CodeMirror {\n",
        "            font-family: \"Source Code Pro\";\n",
        "            font-size: 90%;\n",
        "    }\n",
        "    .prompt {\n",
        "        display: None;\n",
        "    }\n",
        "    .output {\n",
        "        padding-left: 50px;\n",
        "        padding-top: 5px;\n",
        "    }\n",
        "    .output_wrapper {\n",
        "        padding-left: 5px;\n",
        "        padding-top: inherit;\n",
        "    }\n",
        "    div.output_scroll {\n",
        "        width: inherit;\n",
        "    }\n",
        "    .inner_cell {\n",
        "        padding-left: 5px;\n",
        "    }\n",
        "    .text_cell_render h1 {\n",
        "        font-weight: 200;\n",
        "        font-size: 50pt;\n",
        "        line-height: 100%;\n",
        "        color:#CD2305;\n",
        "        margin-bottom: 0.5em;\n",
        "        margin-top: 0.5em;\n",
        "        display: block;\n",
        "    }\n",
        "    .text_cell_render h5 {\n",
        "        font-weight: 300;\n",
        "        font-size: 16pt;\n",
        "        color: #CD2305;\n",
        "        font-style: italic;\n",
        "        margin-bottom: .5em;\n",
        "        margin-top: 0.5em;\n",
        "        display: block;\n",
        "    }\n",
        "    .warning {\n",
        "        color: rgb( 240, 20, 20 )\n",
        "        }  \n",
        "</style>\n",
        "<script>\n",
        "    MathJax.Hub.Config({\n",
        "                        TeX: {\n",
        "                           extensions: [\"AMSmath.js\"]\n",
        "                           },\n",
        "                tex2jax: {\n",
        "                    inlineMath: [ ['$','$'], [\"\\\\(\",\"\\\\)\"] ],\n",
        "                    displayMath: [ ['$$','$$'], [\"\\\\[\",\"\\\\]\"] ]\n",
        "                },\n",
        "                displayAlign: 'center', // Change this to 'center' to center equations.\n",
        "                \"HTML-CSS\": {\n",
        "                    styles: {'.MathJax_Display': {\"margin\": 4}}\n",
        "                }\n",
        "        });\n",
        "</script>"
       ],
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 1,
       "text": [
        "<IPython.core.display.HTML at 0x3927390>"
       ]
      }
     ],
     "prompt_number": 1
    }
   ],
   "metadata": {}
  }
 ]
}